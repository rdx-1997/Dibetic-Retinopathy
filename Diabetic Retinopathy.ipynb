{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diabetic Retinopathy\n",
    "Diabetic retinopathy (DR), also known as diabetic eye disease, is a medical condition in which damage occurs to the retina due to diabetes mellitus. It is a leading cause of blindness. Diabetic retinopathy affects up to 80 percent of those who have had diabetes for 20 years or more. Diabetic retinopathy often has no early warning signs. Retinal (fundus) photography with manual interpretation is a widely accepted screening tool for diabetic retinopathy, with performance that can exceed that of in-person dilated eye examinations.\n",
    "\n",
    "The below figure shows an example of a healthy patient and a patient with diabetic retinopathy as viewed by fundus photography (source):\n",
    "\n",
    "image.png\n",
    "\n",
    "An automated tool for grading severity of diabetic retinopathy would be very useful for accerelating detection and treatment. Recently, there have been a number of attempts to utilize deep learning to diagnose DR and automatically grade diabetic retinopathy. This includes a previous competition and work by Google. Even one deep-learning based system is FDA approved.\n",
    "\n",
    "Clearly, this dataset and deep learning problem is quite important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine being able to detect blindness before it happened.\n",
    "\n",
    "Millions of people suffer from diabetic retinopathy, the leading cause of blindness among working aged adults. Aravind Eye Hospital in India hopes to detect and prevent this disease among people living in rural areas where medical screening is difficult to conduct. Successful entries in this competition will improve the hospital’s ability to identify potential patients. Further, the solutions will be spread to other Ophthalmologists through the 4th Asia Pacific Tele-Ophthalmology Society (APTOS) Symposium\n",
    "\n",
    "Currently, Aravind technicians travel to these rural areas to capture images and then rely on highly trained doctors to review the images and provide diagnosis. Their goal is to scale their efforts through technology; to gain the ability to automatically screen images for disease and provide information on how severe the condition may be.\n",
    "\n",
    "In this synchronous Kernels-only competition, you'll build a machine learning model to speed up disease detection. You’ll work with thousands of images collected in rural areas to help identify diabetic retinopathy automatically. If successful, you will not only help to prevent lifelong blindness, but these models may be used to detect other sorts of diseases in the future, like glaucoma and macular degeneration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description\n",
    "About the Data\n",
    "The images consist of gaussian filtered retina scan images to detect diabetic retinopathy. The original dataset is available at APTOS 2019 Blindness Detection. These images are resized into 224x224 pixels so that they can be readily used with many pre-trained deep learning models.\n",
    "\n",
    "All of the images are already saved into their respective folders according to the severity/stage of diabetic retinopathy using the train.csv file provided. You will find five directories with the respective images:\n",
    "\n",
    "0 - No_DR\n",
    "1 - Mild\n",
    "2 - Moderate\n",
    "3 - Severe\n",
    "4 - Proliferate_DR\n",
    "\n",
    "The dataset contains an export.pkl file which is a ResNet34 model trained on the dataset for 20 epochs using the FastAI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D \n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['diagnosis']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see our data is imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "data_generator=ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=15,\n",
    "                                  width_shift_range=.15,\n",
    "                                  height_shift_range=.15,\n",
    "                                 shear_range =0.2,\n",
    "                                 zoom_range = 0.2,\n",
    "                                  validation_split=0.2, \n",
    "                                 horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3542 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = data_generator.flow_from_directory('C:/Users/HP WORLD/gaussian_filtered_images/train_data',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 128,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = data_generator.flow_from_directory('C:/Users/HP WORLD/gaussian_filtered_images/test_data',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 128,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with this data ,lets do data augmentation of the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gug_data=data_generator.fit(training_set,augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Augmented data train in CNN with different convulation network with batchnormaliztion and dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(16,(3,3),input_shape=(128,128,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattering\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full connection\n",
    "model.add(Dense(224,activation='softmax'))\n",
    "model.add(Dense(5,activation='softmax'))  #output layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_run=model.fit_generator(aug_data,\n",
    "                  steps_per_epoch = 3542,\n",
    "                  epochs = 20,\n",
    "                 validation_data = test_set)\n",
    "CNN_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the training and validation accuracy with respect to the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot):\n",
    "    \n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    #ax.set_ylim(0.28,1.05)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_training_curves(\n",
    "    CNN_run.CNN_run['loss'], \n",
    "    CNN_run['val_loss'], \n",
    "    'loss', 211)\n",
    "display_training_curves(\n",
    "    CNN_run['acc'], \n",
    "    CNN_run['val_acc'], \n",
    "    'accuracy', 212)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
